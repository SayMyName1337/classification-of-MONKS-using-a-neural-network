{
  "params": {
    "n_layers": 2.0,
    "units_first": 128.0,
    "activation": "relu",
    "use_batch_norm": 0.0,
    "dropout_rate": 0.1,
    "use_residual": 0.0,
    "learning_rate": 0.0022885240830054937,
    "batch_size": 8.0,
    "optimizer": "rmsprop",
    "use_regularization": 0.0,
    "l1_factor": 0.0,
    "l2_factor": 0.0
  },
  "layer_config": [
    512,
    256,
    128
  ],
  "val_accuracy": 1.0,
  "epochs_trained": 300
}